{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fd085fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inizio del processo di unione e separazione (Texas) - SAFE MODE...\n",
      "Caricamento di Test/case_law_csv\\cases.csv...\n",
      "Caricamento di Test/case_law_csv\\case_texts.csv...\n",
      "Caricamento di case_details_tx_CLEANED.json (Dataset Pulito)...\n",
      "Caricamento di convictions_with_llm.json...\n",
      "Normalizzazione degli ID...\n",
      "Unione Master: Filtro basato sui casi puliti...\n",
      "Dimensione finale del DataFrame master (Casi Validi): 7791\n",
      "\n",
      "--- SALVATO: File Nodi :Case (leggeri) --- 7791 righe.\n",
      "\n",
      "--- SALVATO: File Nodi :CaseText (pesanti) --- 7791 righe.\n",
      "\n",
      "Caricamento di Test/case_law_csv\\citations.csv per le relazioni :CITES...\n",
      "Citazioni filtrate: da 74756 a 5405 (Rimossi 69351 link a casi sporchi/inesistenti).\n",
      "\n",
      "--- SALVATO: File Relazioni :CITES --- 5405 righe.\n",
      "\n",
      "--- SALVATO: File Relazioni :HAS_TEXT --- 7791 righe.\n",
      "\n",
      " SUCCESS: Processo completato. I file pronti per Neo4j sono in:\n",
      "   -> Test/neo4j_import_separated_tx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_29672\\4182158790.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[id_column] = df[id_column].astype('Int64')\n",
      "C:\\Users\\claud\\AppData\\Local\\Temp\\ipykernel_29672\\4182158790.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[id_column] = df[id_column].astype(str)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# --- NUOVA FUNZIONE DI NORMALIZZAZIONE ---\n",
    "def normalize_id(df, id_column='id'):\n",
    "    \"\"\"Converte in modo sicuro una colonna ID in una stringa pulita, rimuovendo i decimali.\"\"\"\n",
    "    # Forza numerico (gestisce errori), rimuove NaN, converte a int (via Int64 nullable) poi stringa\n",
    "    df[id_column] = pd.to_numeric(df[id_column], errors='coerce')\n",
    "    df = df.dropna(subset=[id_column])\n",
    "    df[id_column] = df[id_column].astype('Int64')\n",
    "    df[id_column] = df[id_column].astype(str)\n",
    "    return df\n",
    "\n",
    "# --- Configurazione ---\n",
    "INPUT_DIR = \"Test/case_law_csv\"  # Assicurati che il percorso sia corretto\n",
    "OUTPUT_DIR = \"Test/neo4j_import_separated_tx\" \n",
    "\n",
    "CASES_CSV = os.path.join(INPUT_DIR, \"cases.csv\")\n",
    "CASE_DETAILS_CSV = os.path.join(INPUT_DIR, \"case_texts.csv\")\n",
    "CITATIONS_CSV = os.path.join(INPUT_DIR, \"citations.csv\")\n",
    "\n",
    "# === MODIFICA QUI: Puntiamo al file PULITO ===\n",
    "LLM_DETAILS_JSON = \"case_details_tx_CLEANED.json\"\n",
    "LLM_CONVICTION_JSON = \"convictions_with_llm.json\"\n",
    "\n",
    "# File di output per Neo4j\n",
    "FINAL_CASES_CSV = os.path.join(OUTPUT_DIR, \"nodes_cases.csv\")\n",
    "FINAL_TEXT_CSV = os.path.join(OUTPUT_DIR, \"nodes_text.csv\")\n",
    "FINAL_CITES_CSV = os.path.join(OUTPUT_DIR, \"edges_citations.csv\")\n",
    "FINAL_HASTEXT_CSV = os.path.join(OUTPUT_DIR, \"edges_has_text.csv\")\n",
    "\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Inizio del processo di unione e separazione (Texas) - SAFE MODE...\")\n",
    "\n",
    "try:\n",
    "    # --- 1. Carichiamo tutti i file ---\n",
    "    print(f\"Caricamento di {CASES_CSV}...\")\n",
    "    df_cases = pd.read_csv(CASES_CSV, dtype={'id': str})\n",
    "    # Teniamo solo colonne utili\n",
    "    df_cases = df_cases[['id', 'name', 'decision_date', 'court_name', 'jurisdiction_name_long', 'parties']]\n",
    "    \n",
    "    print(f\"Caricamento di {CASE_DETAILS_CSV}...\")\n",
    "    df_details = pd.read_csv(CASE_DETAILS_CSV, dtype={'id': str})\n",
    "    \n",
    "    print(f\"Caricamento di {LLM_DETAILS_JSON} (Dataset Pulito)...\")\n",
    "    with open(LLM_DETAILS_JSON, 'r', encoding='utf-8') as f:\n",
    "        data_details_llm = json.load(f)\n",
    "    df_details_llm = pd.DataFrame(data_details_llm)\n",
    "    \n",
    "    # Pulizia colonne extra se presenti\n",
    "    if 'title' in df_details_llm.columns:\n",
    "        df_details_llm = df_details_llm.drop(columns=['title'])\n",
    "\n",
    "    print(f\"Caricamento di {LLM_CONVICTION_JSON}...\")\n",
    "    with open(LLM_CONVICTION_JSON, 'r', encoding='utf-8') as f:\n",
    "        data_conviction_llm = json.load(f)\n",
    "    df_conviction_llm = pd.DataFrame(data_conviction_llm)\n",
    "\n",
    "    # --- 1b. NORMALIZZIAMO TUTTI GLI ID ---\n",
    "    print(\"Normalizzazione degli ID...\")\n",
    "    df_cases = normalize_id(df_cases, 'id')\n",
    "    df_details = normalize_id(df_details, 'id')\n",
    "    df_details_llm = normalize_id(df_details_llm, 'id')\n",
    "    df_conviction_llm = normalize_id(df_conviction_llm, 'id')\n",
    "\n",
    "    # --- 2. Uniamo (Merge) ---\n",
    "    # STRATEGIA IMPORTANTE: Usiamo INNER JOIN sul dataset LLM PULITO.\n",
    "    # Questo elimina automaticamente tutti i casi grezzi che non hanno superato la pulizia.\n",
    "    \n",
    "    print(\"Unione Master: Filtro basato sui casi puliti...\")\n",
    "    \n",
    "    # 1. Unisci Metadati (Cases) con Dettagli LLM (Cleaned) -> INNER JOIN\n",
    "    # Se un caso c'è nel CSV ma non nel JSON pulito, viene scartato qui.\n",
    "    df_master = pd.merge(df_cases, df_details_llm, on='id', how='inner')\n",
    "    \n",
    "    # 2. Unisci il Testo Completo -> INNER JOIN\n",
    "    df_master = pd.merge(df_master, df_details, on='id', how='inner')\n",
    "    \n",
    "    # 3. Unisci Convictions -> LEFT JOIN (Perché alcuni potrebbero mancare, ma non vogliamo perdere il caso)\n",
    "    df_master = pd.merge(df_master, df_conviction_llm, on='id', how='left')\n",
    "\n",
    "    print(f\"Dimensione finale del DataFrame master (Casi Validi): {len(df_master)}\")\n",
    "    \n",
    "    # Creiamo un SET di tutti gli ID validi per filtrare le citazioni\n",
    "    valid_ids_set = set(df_master['id'])\n",
    "\n",
    "    # --- 3. SEPARIAMO il DataFrame master in file di Nodi ---\n",
    "\n",
    "    # File 1: Nodi :Case (leggeri)\n",
    "    # Assicuriamoci che le colonne esistano (anche se vuote)\n",
    "    case_columns = [\n",
    "        'id', 'name', 'decision_date', 'court_name', 'jurisdiction_name_long',\n",
    "        'parties', 'offense', 'punishment', 'decision', 'convicted'\n",
    "    ]\n",
    "    for col in case_columns:\n",
    "        if col not in df_master.columns:\n",
    "            df_master[col] = None\n",
    "            \n",
    "    df_nodes_cases = df_master[case_columns].copy()\n",
    "    \n",
    "    # Rinomina per Neo4j Headers\n",
    "    df_nodes_cases = df_nodes_cases.rename(columns={\n",
    "        'id': 'caseId:ID(Case)', \n",
    "        'decision': 'decisionSummary' # Rinomino per evitare confusione con keywords\n",
    "    })\n",
    "    \n",
    "    # Gestione booleani per Neo4j (True/False invece di 1/0 o float)\n",
    "    df_nodes_cases['convicted'] = df_nodes_cases['convicted'].astype(str).replace({'nan': '', 'None': ''})\n",
    "    \n",
    "    df_nodes_cases.to_csv(FINAL_CASES_CSV, index=False)\n",
    "    print(f\"\\n--- SALVATO: File Nodi :Case (leggeri) --- {len(df_nodes_cases)} righe.\")\n",
    "\n",
    "    # File 2: Nodi :CaseText (pesanti)\n",
    "    text_columns = ['id', 'head_matter', 'opinions']\n",
    "    # Se head_matter non c'è, creala vuota\n",
    "    for col in text_columns:\n",
    "        if col not in df_master.columns:\n",
    "            df_master[col] = \"\"\n",
    "\n",
    "    df_nodes_text = df_master[text_columns].copy()\n",
    "    df_nodes_text = df_nodes_text.rename(columns={\n",
    "        'id': 'textId:ID(CaseText)', \n",
    "        'opinions': 'text'\n",
    "    })\n",
    "    df_nodes_text.to_csv(FINAL_TEXT_CSV, index=False)\n",
    "    print(f\"\\n--- SALVATO: File Nodi :CaseText (pesanti) --- {len(df_nodes_text)} righe.\")\n",
    "    \n",
    "    # --- 4. Creiamo i file delle RELAZIONI ---\n",
    "\n",
    "    # File 3: Relazioni :CITES\n",
    "    print(f\"\\nCaricamento di {CITATIONS_CSV} per le relazioni :CITES...\")\n",
    "    \n",
    "    # Controllo nomi colonne citazioni (adattalo se il tuo CSV ha nomi diversi come 'citing_case_id')\n",
    "    try:\n",
    "        df_edges_cites = pd.read_csv(CITATIONS_CSV, dtype=str)\n",
    "        # Standardizziamo i nomi se necessario\n",
    "        if 'citing_case_id' in df_edges_cites.columns:\n",
    "            df_edges_cites = df_edges_cites.rename(columns={'citing_case_id': 'id1', 'cited_case_id': 'id2'})\n",
    "    except Exception as e:\n",
    "        print(f\"Errore lettura citazioni: {e}\")\n",
    "        df_edges_cites = pd.DataFrame(columns=['id1', 'id2'])\n",
    "\n",
    "    df_edges_cites = normalize_id(df_edges_cites, 'id1')\n",
    "    df_edges_cites = normalize_id(df_edges_cites, 'id2')\n",
    "\n",
    "    # Filtro \"matched\" se presente\n",
    "    if 'matched' in df_edges_cites.columns:\n",
    "        df_edges_cites = df_edges_cites[df_edges_cites['matched'].astype(str).str.lower() == 'true'].copy()\n",
    "    \n",
    "    # --- FILTRO FONDAMENTALE ---\n",
    "    # Manteniamo SOLO le relazioni dove SIA id1 CHE id2 esistono nel nostro set MASTER.\n",
    "    initial_edges = len(df_edges_cites)\n",
    "    df_edges_cites = df_edges_cites[\n",
    "        df_edges_cites['id1'].isin(valid_ids_set) & \n",
    "        df_edges_cites['id2'].isin(valid_ids_set)\n",
    "    ]\n",
    "    final_edges = len(df_edges_cites)\n",
    "    \n",
    "    print(f\"Citazioni filtrate: da {initial_edges} a {final_edges} (Rimossi {initial_edges - final_edges} link a casi sporchi/inesistenti).\")\n",
    "\n",
    "    df_edges_cites = df_edges_cites.rename(columns={\n",
    "        'id1': ':START_ID(Case)',\n",
    "        'id2': ':END_ID(Case)'\n",
    "    })\n",
    "    df_edges_cites[':TYPE'] = 'CITES'\n",
    "    df_edges_cites = df_edges_cites[[':START_ID(Case)', ':END_ID(Case)', ':TYPE']]\n",
    "    \n",
    "    df_edges_cites.to_csv(FINAL_CITES_CSV, index=False)\n",
    "    print(f\"\\n--- SALVATO: File Relazioni :CITES --- {len(df_edges_cites)} righe.\")\n",
    "\n",
    "    # File 4: Nuove Relazioni :HAS_TEXT\n",
    "    df_edges_hastext = df_master[['id']].copy()\n",
    "    df_edges_hastext = df_edges_hastext.rename(columns={\n",
    "        'id': ':START_ID(Case)'\n",
    "    })\n",
    "    df_edges_hastext[':END_ID(CaseText)'] = df_edges_hastext[':START_ID(Case)']\n",
    "    df_edges_hastext[':TYPE'] = 'HAS_TEXT'\n",
    "    \n",
    "    df_edges_hastext.to_csv(FINAL_HASTEXT_CSV, index=False)\n",
    "    print(f\"\\n--- SALVATO: File Relazioni :HAS_TEXT --- {len(df_edges_hastext)} righe.\")\n",
    "\n",
    "    print(\"\\n SUCCESS: Processo completato. I file pronti per Neo4j sono in:\")\n",
    "    print(f\"   -> {OUTPUT_DIR}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"\\n ERRORE: File non trovato: {e.filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n ERRORE GENERICO: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
